# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w61nmqvBX0Hp5RbFnvmrP6bm8NsI0Nj8
"""

!pip install pyngrok
!pip install flask-cors

!ngrok authtoken 2ewZ1XUnKGFmgZhw19xvLPBQ6DJ_2Xj1NvMsrtBwtr7SfFMkP

# Importing necessary libraries and functions
import os
import io
import csv
import joblib
import pandas as pd
import firebase_admin
import google.cloud.storage
from flask_cors import CORS
from pyngrok import ngrok
from flask import Flask, jsonify
from firebase_admin import storage
from flask import Flask, request, jsonify
from firebase_admin import credentials, firestore
from sklearn.feature_extraction.text import CountVectorizer


app = Flask(__name__)
CORS(app)

cred = credentials.Certificate("finify.json")
try:
  firebase_admin.initialize_app(cred, {
    'storageBucket': 'gs://financetracker-2d4b5.appspot.com'
})
except ValueError:
  print("Already Initialized")

@app.route('/classify')
def classify():
  # Obtaining all files present in database
  bucket = storage.bucket('financetracker-2d4b5.appspot.com')
  blobs = bucket.list_blobs(prefix=folder_path)
  csv_files = [blob.name for blob in blobs if blob.name.endswith('.csv')]

  # Reading the CSV files
  dfs = []
  for csv_file in csv_files:
      blob = bucket.blob(csv_file)
      local_file_path = f"/tmp/{csv_file.split('/')[-1]}"
      blob.download_to_filename(local_file_path)
      try:
          df = pd.read_csv(local_file_path)
          dfs.append(df)
      except pd.errors.ParserError as e:
          print(f"Error reading {csv_file}: {e}. Skipping this file.")

  #Creating overall Dataframe
  combined_df = pd.concat(dfs)
  combined_df = combined_df.drop_duplicates()

  print("All CSV files read and duplicates removed successfully.")

  #Loading Trained ML Model: MultinomialNB
  model = 'model.pkl'
  classifier, vectorizer = joblib.load(model)

  # Applying ML Algorithm on the file
  new_texts = combined_df['text'].tolist()
  new_features = vectorizer.transform(new_texts)
  new_predictions = classifier.predict(new_features)
  combined_df[['class', 'subclass']] = pd.DataFrame(new_predictions, columns=['class', 'subclass'])

  # Categorizing into Income & Expense
  income_classes = ['credit']
  expense_classes = ['payments', 'withdrawl','purchase']
  combined_df['category'] = combined_df['class'].map(lambda x: 'income' if x in income_classes else ('expense' if x in expense_classes else 'others'))

  # Saving the Report to Firebase
  csv_data = combined_df.to_csv(index=False)
  csv_bytes = csv_data.encode('utf-8')
  storage_path = f"output/{username}/report.csv"
  blob = bucket.blob(storage_path)
  blob.upload_from_string(csv_bytes, content_type='text/csv')

  try:
    blob.upload_from_string(csv_bytes, content_type='text/csv', if_generation_match=None)

  except PreconditionFailed:
    # Overwrite the existing file
    blob.upload_from_string(csv_bytes, content_type='text/csv', if_generation_match=None)

@app.route('/')
def home():
  return 'Hello, world! This is your Flask app running on ngrok.'

@app.route('/favicon.ico')
def favicon():
  return '', 404

if __name__ == '__main__':
    # Start ngrok tunnel
    ngrok_tunnel = ngrok.connect(8000)
    print('Public URL:', ngrok_tunnel.public_url)

    # Run Flask app
    app.run(port=8000)

